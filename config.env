PATCH_SIZE=128
BATCH_SIZE=1
NUM_WORKERS=0
DATA_PATH = ./ATM22/npy_files/
PREFETCH_FACTOR=1
PIN_MEMORY=False
MIXED_PRECISION=True
SPATIAL_DIMS=3
IN_CHANNELS=1
OUT_CHANNELS=1
N_LAYERS=4
CHANNELS=16
STRIDES=2
NUM_RES_UNITS=2
DROPOUT=0.2
NORM=INSTANCE
# Available models: SimpleResUNet, BasicUNet, AttentionUNet, WingsNet
MODEL_NAME=AttentionUNet
LOSS_FUNC=DiceLoss
ALPHA_VALUE=0.3
PATIENCE=7
OPTIMIZER=AdamW
LR=0.0001
PIXEL_VALUE_MIN=-1000
PIXEL_VALUE_MAX=400
PIXEL_NORM_MIN=0.0
PIXEL_NORM_MAX=1.0
SCHEDULER_TYPE=WarmupCosineSchedule
NUM_EPOCHS=100
MAX_CARDINALITY=255
OUTPUT_PATH=./outputs/
DATASET_PATH=./ATM22/npy_files/
DEVICE_NO=0
GRADIENT_CHECKPOINTING=True
# Dataset and caching configuration
CACHE_DATASET=False
# Force cache to be cleared on next run
CLEAN_CACHE=False

# Debug control for topology metrics (fixes performance bottleneck)
# Options: 'none', 'minimal', 'detailed', 'full'
# - none: No debug output
# - minimal: Only summary (1-2 lines)
# - detailed: Shows top components (default, ~10-15 lines)
# - full: Shows all components (use only for debugging, can be very slow)
DEBUG_TOPOLOGY_METRICS=none
# Maximum number of components to show in detailed mode
MAX_DEBUG_COMPONENTS=10
# Warning threshold for excessive components (indicates noisy predictions)
MAX_COMPONENTS_THRESHOLD=50000
USE_PATCH_BANK_SAMPLING=True
PATCH_BANKS_DIR=./ATM22/npy_files/patch_banks/
SAMPLER_POS_RATIO=0.9
SAMPLER_TEMPERATURE=1.0
SAMPLER_FG_THRESHOLD=4.72e-05
# Fine-tune defaults (optional)
# When fine-tuning from checkpoint with new sampling, consider lowering LR by 5-10x
FINETUNE_FROM=
FINETUNE_LR_SCALE=0.2
PERSISTENT_DATASET=True